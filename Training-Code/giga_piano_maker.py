# -*- coding: utf-8 -*-
"""GIGA_Piano_Maker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ke-zRKRTbrfTmqbOFbdlkDW_eu97Mg3P

# GIGA Piano Maker (ver. 1.0)

***

Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools

***

Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch

***

WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/

***

#### Project Los Angeles

#### Tegridy Code 2022

***

# (Setup Environment)
"""

#@title nvidia-smi gpu check
!nvidia-smi

#@title Install all dependencies (run only once per session)

!git clone https://github.com/asigalov61/GIGA-Piano

!pip install torch

!pip install tqdm
!pip install matplotlib

#@title Import all needed modules

print('Loading needed modules. Please wait...')
import os
import random
import secrets
from collections import OrderedDict

from tqdm import tqdm

import matplotlib.pyplot as plt

from torchsummary import summary

if not os.path.exists('/content/Dataset'):
    os.makedirs('/content/Dataset')

print('Loading core modules...')
os.chdir('/content/GIGA-Piano')

import TMIDIX
from GPT2RGAX import *

os.chdir('/content/')

"""# (FROM SCRATCH) Download Sample Piano Datasets"""

# Commented out IPython magic to ensure Python compatibility.
#@title ALL-Piano Dataset
# %cd /content/Dataset/
!wget --no-check-certificate -O 'ALL-Piano.zip' "https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118569&authkey=AAYVqXUlxXmpFqk"
!unzip ALL-Piano.zip
!rm ALL-Piano.zip
# %cd /content/

# Commented out IPython magic to ensure Python compatibility.
#@title GiantMIDI Dataset
# %cd /content/Dataset/
!wget --no-check-certificate -O 'GiantMIDI.zip' "https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118494&authkey=AJr3wBuauBiEzVQ"
!unzip GiantMIDI.zip
!rm GiantMIDI.zip
# %cd /content/

# Commented out IPython magic to ensure Python compatibility.
#@title MAESTRO Dataset
# %cd /content/Dataset/
!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip
!unzip maestro-v3.0.0-midi.zip
!rm maestro-v3.0.0-midi.zip
# %cd /content/

"""# (PROCESS MIDIs)"""

#@title Process MIDIs with TMIDIX MIDI Processor

#@title Process MIDIs

sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended
dataset_ratio = 1 # Change this if you need more data


print('TMIDIX MIDI Processor')
print('Starting up...')
###########

files_count = 0

gfiles = []

melody_chords_f = []

###########

print('Loading MIDI files...')
print('This may take a while on a large dataset in particular.')

dataset_addr = "/content/Dataset"
# os.chdir(dataset_addr)
filez = list()
for (dirpath, dirnames, filenames) in os.walk(dataset_addr):
    filez += [os.path.join(dirpath, file) for file in filenames]
print('=' * 70)

if filez == []:
    print('Could not find any MIDI files. Please check Dataset dir...')
    print('=' * 70)

if sorted_or_random_file_loading_order:
    print('Sorting files...')
    filez.sort()
    print('Done!')
    print('=' * 70)
else:
    print('Randomizing file list...')
    random.shuffle(filez)


print('Processing MIDI files. Please wait...')
for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):
    try:
        fn = os.path.basename(f)
        fn1 = fn.split('.')[0]

        #print('Loading MIDI file...')
        score = TMIDIX.midi2ms_score(open(f, 'rb').read())

        events_matrix = []

        itrack = 1

        while itrack < len(score):
            for event in score[itrack]:         
                if event[0] == 'note' and event[3] != 9:
                    events_matrix.append(event)
            itrack += 1
        
        if len(events_matrix) >= 256:

          # Sorting...
          events_matrix.sort(key=lambda x: x[4], reverse=True)
          events_matrix.sort(key=lambda x: x[1])

          # recalculating timings
          for e in events_matrix:
              e[1] = int(e[1] / 16)
              e[2] = int(e[2] / 32)
          
          # final processing...

          melody_chords = []

          pe = events_matrix[0]
          for e in events_matrix:

              time = max(0, min(126, e[1]-pe[1]))
              dur = max(1, min(126, e[2]))

              ptc = max(1, min(126, e[4]))

              melody_chords.append([time, dur, ptc])

              pe = e

          melody_chords_f.append(melody_chords)
          files_count += 1
        
    except KeyboardInterrupt:
        print('Quitting...')
        break  

    except:
        print('Bad MIDI:', f)
        continue

print('=' * 70)
TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/GIGA_Piano_Processed_MIDIs')        
print('Done!')   
print('=' * 70)

"""# (FILTER AND PREP DATA)"""

#@title Filter music and prep resulting data

clen = 256 # Length of data chunks in notes

# 256 notes == 1024 seq_len

repmin = 54 # Minimum repeating patterns in each chunk

chunks = []
total1 = 0

print('=' * 70)
print('Filtering and prepping data...')
print('=' * 70)

for m in tqdm(melody_chords_f):
  if len(m) >= clen:
    for i in range(0, (len(m) // clen) * clen, clen):
      data = m[i:i+clen]
      total1 += 1
      if len(data) == clen: # Checking chunk length
        if len(list(set(tuple(i) for i in data))) > repmin: # Filtering out repetitions
          if 0 in list(set([y[0] for y in data])): # Filtering out all melody chunks
            length = sum([y[0] for y in data])
            if length > clen and length < 100 * clen: # Filtering out extra fast and extra slow chunks
              chunks.append(data)

print('Done!')
print('=' * 70)
print('Total input chunks:', total1)
print('Total output chunks:', len(chunks))
print('Total filtered out chunks:', total1-len(chunks))
print('=' * 70)

#@title Finalize the data and prep INTs
train_data1 = []

print('=' * 70)
print('Finalizing data and prepping INTs...')
print('=' * 70)

print('Randomizing data chunks...')
print('=' * 70)
random.shuffle(chunks)

print('Prepping INTs...')
print('=' * 70)

for i in tqdm(range(len(chunks))):
  for c in chunks[i]:
    train_data1.append(127)
    train_data1.extend([c[0], c[1], c[2]])

print('Done!')
print('=' * 70)
TMIDIX.Tegridy_Any_Pickle_File_Writer(train_data1, '/content/GIGA_Piano_INTs')

"""# (TEST INTs)"""

#@title Test resulting INTs

print('=' * 70)
print('Sample INTs', train_data1[:15])
print('=' * 70)

idx = random.randint(0, len(train_data1) // 1024)

out1 = train_data1[1024*idx:1024*(idx+1)]

if len(out1) != 0:
    
    song = out1
    song_f = []
    time = 0
    dur = 0
    vel = 0
    pitch = 0
    channel = 0

    son = []

    song1 = []

    for s in song:
      if s != 127:
        son.append(s)

      else:
        if len(son) == 3:
          song1.append(son)
        son = []
        #son.append(s)
    
    for s in song1:

        channel = 0

        vel = 90

        time += s[0] * 16
            
        dur = s[1] * 32
        
        pitch = s[2]
                                  
        song_f.append(['note', time, dur, channel, pitch, vel ])

    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,
                                                        output_signature = 'GIGA Piano',  
                                                        output_file_name = '/content/GIGA-Piano-Music-Composition', 
                                                        track_name='Project Los Angeles',
                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 0, 0, 0, 0, 0],
                                                        number_of_ticks_per_quarter=500)

    print('Done!')

"""# (TRAIN)"""

#@title Load processed INTs dataset

SEQ_LEN = max_seq

BATCH_SIZE = 4 # Change this to your specs

# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs

print('=' * 50)
print('Loading training data...')

data_train, data_val = torch.LongTensor(train_data1), torch.LongTensor(train_data1)

class MusicSamplerDataset(Dataset):
    def __init__(self, data, seq_len):
        super().__init__()
        self.data = data
        self.seq_len = seq_len

    def __getitem__(self, index):

        rand = secrets.randbelow((self.data.size(0)-(self.seq_len)) // (self.seq_len)) * (self.seq_len)

        x = self.data[rand: rand + self.seq_len].long()
        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()
        
        return x, trg

    def __len__(self):
        return self.data.size(0)

train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)
val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)
train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)
val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)

print('=' * 50)
print('Total INTs in the dataset', len(train_data1))
print('Total unique INTs in the dataset', len(set(train_data1)))
print('Max INT in the dataset', max(train_data1))
print('Min INT in the dataset', min(train_data1))
print('=' * 50)
print('Length of the dataset:',len(train_dataset))
print('Number of batched samples per epoch:', len(train_data1) // max_seq // BATCH_SIZE)
print('=' * 50)
print('Sample train dataset:', train_dataset[0])
print('Sample val dataset:', val_dataset[0])
print('=' * 50)
print('Train loader length:', len(train_loader))
print('Val loader length:', len(val_loader))
print('=' * 50)
print('Done! Enjoy! :)')
print('=' * 50)

#@title Train the model

DIC_SIZE = 128

# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs

config = GPTConfig(DIC_SIZE, 
                   max_seq,
                   dim_feedforward=1024,
                   n_layer=16, 
                   n_head=16, 
                   n_embd=1024,
                   enable_rpr=True,
                   er_len=max_seq)

# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = GPT(config)

model = nn.DataParallel(model) # Multi-GPU training...

model.to(device)

#=====

init_step = 0
lr = LR_DEFAULT_START
lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)
eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)
train_loss_func = eval_loss_func

opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)
lr_scheduler = LambdaLR(opt, lr_stepper.step)


#===

best_eval_acc        = 0.0
best_eval_acc_epoch  = -1
best_eval_loss       = float("inf")
best_eval_loss_epoch = -1
best_acc_file = '/content/gpt2_rpr_acc.pth'
best_loss_file = '/content/gpt2_rpr_loss.pth'
loss_train, loss_val, acc_val = [], [], []

for epoch in range(0, epochs):
    new_best = False
    
    loss = train(epoch+1, 
                 model, train_loader, 
                 train_loss_func, 
                 opt, 
                 lr_scheduler, 
                 num_iters=-1, 
                 save_checkpoint_steps=4000)
    
    loss_train.append(loss)
    
    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)
    loss_val.append(eval_loss)
    acc_val.append(eval_acc)
    
    if(eval_acc > best_eval_acc):
        best_eval_acc = eval_acc
        best_eval_acc_epoch  = epoch+1
        torch.save(model.state_dict(), best_acc_file)
        new_best = True

    if(eval_loss < best_eval_loss):
        best_eval_loss       = eval_loss
        best_eval_loss_epoch = epoch+1
        torch.save(model.state_dict(), best_loss_file)
        new_best = True
    
    if(new_best):
        print("Best eval acc epoch:", best_eval_acc_epoch)
        print("Best eval acc:", best_eval_acc)
        print("")
        print("Best eval loss epoch:", best_eval_loss_epoch)
        print("Best eval loss:", best_eval_loss)

#@title Eval funct to eval separately if needed

#=====

init_step = 0
lr = LR_DEFAULT_START
lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)
eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)
train_loss_func = eval_loss_func

opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)
lr_scheduler = LambdaLR(opt, lr_stepper.step)


eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)

"""# (MODEL SAVE/LOAD)"""

#@title Save the model

print('Saving the model...')
full_path_to_model_checkpoint = "/contentGIGA-Piano-Trained-Model.pth" #@param {type:"string"}
torch.save(model.state_dict(), full_path_to_model_checkpoint)
print('Done!')

"""# Congrats! You did it! :)"""